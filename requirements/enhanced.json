{
  "feature": "live-analysis",
  "version": "2.0.0",
  "name": "Live Analysis",
  "product": "AI Notes",
  "summary": "End-to-end real-time transcription + client sentiment (text+tone) + pain points + objections + next-best-action coaching for sales calls. Supports Web and Desktop clients.",
  "targetPlatforms": ["web", "desktop"],
  "primaryUseCase": {
    "scenario": "Salesperson speaking with a client on a live call (Teams/Zoom/Meet/Phone).",
    "goal": "Give the salesperson real-time visibility into client perception and actionable suggestions to improve the chance of closing."
  },

  "platformSupport": {
    "web": {
      "audioCapture": {
        "sources": [
          {
            "id": "mic",
            "type": "microphone",
            "supported": true,
            "notes": "Guaranteed for web via getUserMedia; good baseline."
          },
          {
            "id": "tabAudio",
            "type": "tabAudioOptional",
            "supported": "bestEffort",
            "notes": "If user shares a tab, browser may provide tab audio; system audio is inconsistent across browsers."
          }
        ],
        "quality": {
          "preferredSampleRateHz": 16000,
          "channels": 1,
          "encoding": "pcm_s16le",
          "frameMs": 20,
          "packetMs": 1000
        },
        "roleSeparationStrategy": {
          "preferred": "userRoleBySource",
          "rules": [
            { "sourceId": "mic", "role": "SALES" },
            { "sourceId": "tabAudio", "role": "CLIENT_OR_MIXED" }
          ],
          "fallbacks": ["speakerClusteringPlusUserMapping"]
        }
      }
    },

    "desktop": {
      "audioCapture": {
        "sources": [
          {
            "id": "mic",
            "type": "microphone",
            "supported": true
          },
          {
            "id": "system",
            "type": "systemAudioLoopback",
            "supported": true,
            "notes": "Recommended for Teams/Zoom/etc. to separate client audio (system) from sales audio (mic)."
          }
        ],
        "quality": {
          "preferredSampleRateHz": 16000,
          "channels": 1,
          "encoding": "pcm_s16le",
          "frameMs": 20,
          "packetMs": 1000
        },
        "roleSeparationStrategy": {
          "preferred": "strictBySource",
          "rules": [
            { "sourceId": "mic", "role": "SALES" },
            { "sourceId": "system", "role": "CLIENT" }
          ],
          "fallbacks": ["speakerClusteringPlusUserMapping"]
        }
      }
    }
  },

  "architecture": {
    "components": {
      "client": [
        "AudioCapture",
        "VAD",
        "Chunker",
        "ProsodyFeatureExtractor(optional)",
        "RealtimeTransportClient(WS/SSE fallback)",
        "LiveAnalysisUI"
      ],
      "backend": [
        "Auth & Session Service",
        "Realtime Gateway (WebSocket)",
        "Audio Ingest Service",
        "ASR Proxy (ElevenLabs Realtime STT)",
        "Transcript Normalizer/Deduper",
        "Prosody Scoring (if server-side)",
        "Analysis Orchestrator (15s cadence)",
        "LLM Provider Adapter",
        "Meeting Memory Store",
        "Event Stream Fanout",
        "Compliance/Redaction Service",
        "Observability (logs/metrics/tracing)"
      ],
      "externalProviders": [
        {
          "name": "ElevenLabs",
          "usage": "Realtime speech-to-text (streaming)",
          "model": "scribe-v2-realtime",
          "mode": "backendProxyRecommended"
        },
        {
          "name": "LLM",
          "usage": "Sentiment + pain points + coaching",
          "providers": ["OpenAI|Anthropic|Groq|Local"],
          "notes": "Pluggable. Must output strict JSON."
        }
      ]
    },
    "dataFlow": [
      "Client captures audio -> VAD -> chunk -> send audio.chunk to backend WS",
      "Backend forwards audio to ASR provider -> receives partial/committed transcripts",
      "Backend normalizes + dedupes -> emits asr.partial/asr.final to UI",
      "Every 15s backend runs analysis loop using committed transcript deltas + prosody + meeting memory",
      "Backend emits analysis.metrics + analysis.coach + analysis.insight to UI"
    ]
  },

  "realtimeTransport": {
    "primary": "websocket",
    "fallback": "sse",
    "reconnect": {
      "enabled": true,
      "maxRetries": 12,
      "backoffMs": [250, 500, 1000, 2000, 4000, 8000],
      "resume": {
        "useLastAckedSeq": true,
        "dedupeByUtteranceId": true
      }
    },
    "latencyTargets": {
      "partialTranscriptP95Ms": 1500,
      "committedTranscriptP95Ms": 3000,
      "analysisUpdateP95Ms": 5000
    }
  },

  "audioProcessing": {
    "vad": {
      "enabled": true,
      "location": "client",
      "minSpeechMs": 250,
      "finalizeOnSilenceMs": 800,
      "dropSilenceChunks": true
    },
    "chunking": {
      "frameMs": 20,
      "packetMs": 1000,
      "maxBufferedMs": 5000,
      "backpressurePolicy": "dropOldestPartialsKeepFinals"
    },
    "prosody": {
      "enabled": true,
      "computeLocation": "clientPreferred_serverFallback",
      "windowSec": 6,
      "strideSec": 2,
      "features": [
        "rmsEnergy",
        "pitchF0Mean",
        "pitchF0Variance",
        "speechRateProxy",
        "pauseRatio",
        "fillerWordRate"
      ],
      "qualityGates": {
        "minVoicedMs": 800,
        "minSNRDb": 10,
        "ifFail": "disableToneWeightsReduceConfidence"
      },
      "outputs": [
        { "key": "clientEnergy", "range": [0, 1] },
        { "key": "clientStress", "range": [0, 1] },
        { "key": "clientCertainty", "range": [0, 1] }
      ]
    }
  },

  "speakerRoleHandling": {
    "speakerRoles": ["SALES", "CLIENT", "UNKNOWN", "MIXED"],
    "preferredMode": "roleByAudioSource",
    "fallbackMode": "speakerClusteringPlusUserMapping",
    "fallback": {
      "maxSpeakers": 2,
      "userMappingPrompt": "Select which speaker is you (Sales).",
      "persistForMeeting": true,
      "confidenceModel": "clusterStabilityOverTime"
    },
    "analysisRule": {
      "sentimentPrimaryTarget": "CLIENT",
      "ignoreForClientSentiment": ["SALES"],
      "ifRoleUnknown": "computeMixedButLowerConfidence"
    }
  },

  "asr": {
    "provider": {
      "primary": {
        "name": "elevenlabs",
        "mode": "realtime_stt_websocket",
        "model": "scribe-v2-realtime",
        "integration": "backend_proxy",
        "eventsExpected": ["partial", "committed"],
        "keyManagement": "serverOnly"
      },
      "fallback": {
        "name": "local_whisper_wasm_or_server_asr",
        "mode": "optional",
        "notes": "Use if ElevenLabs quota exceeded or offline mode enabled."
      }
    },
    "normalization": {
      "utteranceIdStrategy": "providerUtteranceIdOrHash(tsStart,tsEnd,speaker,source)",
      "dedupe": {
        "dedupeKey": "utteranceId",
        "partialReplacePolicy": "replaceSameUtteranceId",
        "finalImmutability": true
      }
    }
  },

  "analysisLoop": {
    "cadenceSec": 15,
    "inputs": {
      "useCommittedOnly": true,
      "deltaWindowSec": 15,
      "contextWindowSec": 120,
      "includeProsody": true,
      "includeTalkDynamics": true,
      "includeTopicCoverage": true
    },
    "meetingMemory": {
      "enabled": true,
      "refreshEverySec": 60,
      "maxChars": 2500,
      "fields": [
        "summary",
        "painPoints",
        "objections",
        "constraints",
        "budgetSignals",
        "timelineSignals",
        "decisionMakerSignals",
        "competitorMentions",
        "securityConcerns",
        "nextSteps",
        "promisesMade"
      ],
      "storage": {
        "type": "serverMemoryPlusOptionalDB",
        "persistOnMeetingEnd": true
      }
    },
    "metrics": {
      "clientValence": { "range": [-1, 1], "confidenceRange": [0, 1] },
      "clientEngagement": { "range": [0, 1], "confidenceRange": [0, 1] },
      "callHealth": { "range": [0, 100], "confidenceRange": [0, 1] },
      "riskFlags": {
        "types": [
          "priceObjection",
          "timingObjection",
          "trustConcern",
          "featureGap",
          "securityConcern",
          "integrationConcern",
          "competitorMention",
          "confusion",
          "frustration",
          "lowEngagement",
          "scopeMismatch"
        ],
        "severity": ["low", "medium", "high"]
      },
      "painPoints": {
        "maxItems": 5,
        "schema": {
          "title": "string",
          "detail": "string",
          "category": "cost|time|risk|integration|compliance|usability|performance|trust|support|other",
          "confidence": "number(0..1)",
          "evidenceUtteranceIds": "string[]"
        }
      },
      "talkDynamics": {
        "talkRatioSalesPct": "0..100",
        "talkRatioClientPct": "0..100",
        "interruptionsCount": "0..999",
        "paceWpmSales": "0..300",
        "paceWpmClient": "0..300"
      },
      "topicCoverage": {
        "topics": [
          "needProblem",
          "budget",
          "timeline",
          "decisionMaker",
          "alternativesCompetitors",
          "technicalFit",
          "securityCompliance",
          "procurement",
          "nextSteps"
        ]
      },
      "toneSignals": {
        "use": ["clientEnergy", "clientStress", "clientCertainty"],
        "notes": "Only applied when prosody quality gates pass."
      }
    },
    "fusion": {
      "clientValence": {
        "textWeight": 0.75,
        "toneWeight": 0.25,
        "toneAppliesOnlyIf": "prosodyQualityPass"
      },
      "clientEngagement": {
        "dynamicsWeight": 0.6,
        "toneWeight": 0.4,
        "toneAppliesOnlyIf": "prosodyQualityPass"
      },
      "confidence": {
        "inputs": [
          "asrConfidence",
          "speakerRoleCertainty",
          "prosodyQuality",
          "deltaCompleteness"
        ],
        "output": "0..1"
      }
    },
    "coachOutputs": {
      "nextBestSay": { "maxItems": 3, "mustIncludeEvidence": true },
      "nextQuestions": { "maxItems": 3, "mustIncludeEvidence": true },
      "doDont": { "maxItems": 4, "mustIncludeEvidence": true },
      "closingGuidance": {
        "enabled": true,
        "notes": "Only provide if buying signals detected; avoid pushy manipulation."
      }
    },
    "uiUpdatePolicy": {
      "cooldownSec": 8,
      "minConfidenceToUpdate": 0.55,
      "avoidFlicker": {
        "smoothing": "ema",
        "alpha": 0.35
      }
    }
  },

  "aiIntegration": {
    "mode": "serverOrchestrated",
    "providers": {
      "primary": "pluggable",
      "fallback": "pluggable"
    },
    "privacyMode": {
      "enabled": true,
      "behavior": {
        "sendAudio": false,
        "sendTranscript": true,
        "sendProsody": true,
        "redactPII": true
      }
    },
    "prompts": {
      "strictJsonOutput": true,
      "rules": [
        "Use only provided transcript and meeting memory; do not invent product facts.",
        "Avoid manipulative tactics; provide ethical coaching.",
        "Always include evidence utterance IDs for claims (pain points, objections, suggestions).",
        "If unsure, lower confidence and ask clarifying question suggestions."
      ]
    },
    "requestTemplates": {
      "analysisEvery15s": {
        "input": {
          "meetingId": "string",
          "deltaCommittedUtterances": "array<Utterance>",
          "contextSummary": "string",
          "recentClientProsody": "object(optional)",
          "talkDynamicsWindow": "object",
          "topicCoverageState": "object",
          "currentRiskFlags": "array"
        },
        "expectedOutputSchema": {
          "clientValence": "number(-1..1)",
          "clientValenceConfidence": "number(0..1)",
          "clientEngagement": "number(0..1)",
          "clientEngagementConfidence": "number(0..1)",
          "painPoints": "array<PainPoint>",
          "objections": "array<Objection>",
          "riskFlags": "array<RiskFlag>",
          "nextBestSay": "array<Suggestion>",
          "nextQuestions": "array<Suggestion>",
          "doDont": "array<DoDont>",
          "evidence": "array<EvidenceSnippet>",
          "updatedMeetingMemoryPatch": "object"
        }
      }
    }
  },

  "eventProtocol": {
    "envelope": {
      "fields": [
        "eventId",
        "type",
        "meetingId",
        "tsMs",
        "seq",
        "payload",
        "traceIdOptional"
      ]
    },
    "clientToServer": [
      {
        "type": "control.liveAnalysis.start",
        "payload": {
          "meetingId": "string",
          "platform": "web|desktop",
          "enabledSources": "string[]",
          "privacyMode": "boolean",
          "sensitivity": "number(0..100)",
          "coachingAggressiveness": "number(0..100)"
        }
      },
      {
        "type": "control.liveAnalysis.stop",
        "payload": { "meetingId": "string" }
      },
      {
        "type": "audio.chunk",
        "payload": {
          "meetingId": "string",
          "sourceId": "mic|system|tabAudio",
          "seq": "number",
          "tsStartMs": "number",
          "tsEndMs": "number",
          "encoding": "pcm_s16le",
          "sampleRateHz": 16000,
          "channels": 1,
          "vadState": "speech|silence",
          "bytesBase64": "string"
        }
      },
      {
        "type": "prosody.frame",
        "payload": {
          "meetingId": "string",
          "sourceId": "system|tabAudio|mic",
          "assumedRole": "CLIENT|SALES|UNKNOWN",
          "windowTsStartMs": "number",
          "windowTsEndMs": "number",
          "features": {
            "rmsEnergy": "number",
            "pitchF0Mean": "number",
            "pitchF0Variance": "number",
            "speechRateProxy": "number",
            "pauseRatio": "number",
            "fillerWordRate": "number"
          },
          "quality": { "snrDb": "number", "voicedMs": "number" }
        }
      },
      {
        "type": "feedback.suggestion",
        "payload": {
          "meetingId": "string",
          "itemId": "string",
          "itemType": "nextBestSay|nextQuestion|doDont",
          "rating": "up|down",
          "commentOptional": "string"
        }
      },
      {
        "type": "control.speakerMapping",
        "payload": {
          "meetingId": "string",
          "mapping": [{ "speakerId": "string", "role": "SALES|CLIENT" }]
        }
      }
    ],
    "serverToClient": [
      {
        "type": "stream.status",
        "payload": {
          "meetingId": "string",
          "status": "idle|connecting|live|reconnecting|error",
          "latencyMs": "number",
          "messageOptional": "string"
        }
      },
      {
        "type": "asr.partial",
        "payload": {
          "meetingId": "string",
          "utteranceId": "string",
          "speakerId": "string",
          "speakerRole": "SALES|CLIENT|UNKNOWN|MIXED",
          "sourceId": "mic|system|tabAudio",
          "tsStartMs": "number",
          "tsEndMs": "number",
          "text": "string",
          "confidence": "number(0..1)"
        }
      },
      {
        "type": "asr.final",
        "payload": {
          "meetingId": "string",
          "utteranceId": "string",
          "speakerId": "string",
          "speakerRole": "SALES|CLIENT|UNKNOWN|MIXED",
          "sourceId": "mic|system|tabAudio",
          "tsStartMs": "number",
          "tsEndMs": "number",
          "text": "string",
          "confidence": "number(0..1)"
        }
      },
      {
        "type": "analysis.metrics",
        "payload": {
          "meetingId": "string",
          "windowTsStartMs": "number",
          "windowTsEndMs": "number",
          "clientValence": "number(-1..1)",
          "clientValenceConfidence": "number(0..1)",
          "clientEngagement": "number(0..1)",
          "clientEngagementConfidence": "number(0..1)",
          "clientEnergy": "number(0..1)",
          "clientStress": "number(0..1)",
          "clientCertainty": "number(0..1)",
          "toneConfidence": "number(0..1)",
          "callHealth": "number(0..100)",
          "callHealthConfidence": "number(0..1)",
          "riskFlags": [
            {
              "type": "string",
              "severity": "low|medium|high",
              "confidence": "number(0..1)",
              "evidenceUtteranceIds": "string[]"
            }
          ],
          "talkDynamics": {
            "talkRatioSalesPct": "number(0..100)",
            "talkRatioClientPct": "number(0..100)",
            "interruptionsCount": "number",
            "paceWpmSales": "number",
            "paceWpmClient": "number"
          },
          "topicCoverage": {
            "checkedTopics": "string[]",
            "confidenceByTopic": "record<string, number>"
          }
        }
      },
      {
        "type": "analysis.insight",
        "payload": {
          "meetingId": "string",
          "insightId": "string",
          "timestampMs": "number",
          "type": "painPoint|objection|risk|positiveSignal|topic|coach",
          "severity": "low|medium|high",
          "title": "string",
          "detail": "string",
          "confidence": "number(0..1)",
          "evidence": [
            {
              "utteranceId": "string",
              "speakerRole": "SALES|CLIENT|UNKNOWN|MIXED",
              "tsStartMs": "number",
              "tsEndMs": "number",
              "text": "string"
            }
          ]
        }
      },
      {
        "type": "analysis.coach",
        "payload": {
          "meetingId": "string",
          "generatedAtMs": "number",
          "nextBestSay": [
            {
              "id": "string",
              "text": "string",
              "intent": "addressObjection|clarify|valueReinforce|close|discovery|rapport",
              "confidence": "number(0..1)",
              "evidenceUtteranceIds": "string[]"
            }
          ],
          "nextQuestions": [
            {
              "id": "string",
              "text": "string",
              "intent": "discovery|budget|timeline|dm|risk|close",
              "confidence": "number(0..1)",
              "evidenceUtteranceIds": "string[]"
            }
          ],
          "doDont": [
            {
              "id": "string",
              "type": "do|dont",
              "text": "string",
              "confidence": "number(0..1)",
              "evidenceUtteranceIds": "string[]"
            }
          ],
          "painPoints": [
            {
              "title": "string",
              "detail": "string",
              "category": "cost|time|risk|integration|compliance|usability|performance|trust|support|other",
              "confidence": "number(0..1)",
              "evidenceUtteranceIds": "string[]"
            }
          ]
        }
      }
    ]
  },

  "ui": {
    "section": {
      "name": "Live Analysis",
      "route": "/meeting/:meetingId/live-analysis",
      "entryPoints": ["meetingLiveView", "meetingControlsPanel"]
    },
    "panels": [
      {
        "id": "meters",
        "type": "metricsRow",
        "items": [
          {
            "key": "clientValence",
            "label": "Client Sentiment",
            "visual": "gaugeWithTrend",
            "range": [-1, 1],
            "showConfidence": true
          },
          {
            "key": "clientEngagement",
            "label": "Engagement",
            "visual": "gaugeWithTrend",
            "range": [0, 1],
            "showConfidence": true
          },
          {
            "key": "clientEnergy",
            "label": "Energy (Tone)",
            "visual": "gaugeWithTrend",
            "range": [0, 1],
            "showConfidence": true
          },
          {
            "key": "callHealth",
            "label": "Call Health",
            "visual": "scoreWithTrend",
            "range": [0, 100],
            "showConfidence": true
          },
          { "key": "riskFlags", "label": "Flags", "visual": "chips" }
        ]
      },
      {
        "id": "coach",
        "type": "coachPanel",
        "sections": [
          { "key": "nextBestSay", "label": "Say this next", "maxItems": 3 },
          { "key": "nextQuestions", "label": "Ask next", "maxItems": 3 },
          { "key": "doDont", "label": "Do / Don't", "maxItems": 4 },
          {
            "key": "painPoints",
            "label": "Pain points detected",
            "maxItems": 5
          }
        ],
        "actions": [
          { "id": "copy", "label": "Copy" },
          { "id": "markUsed", "label": "Mark used" },
          { "id": "feedback", "label": "Helpful?" }
        ]
      },
      {
        "id": "timeline",
        "type": "insightsTimeline",
        "shows": [
          "objections",
          "painPoints",
          "sentimentDrops",
          "competitorMentions",
          "keyTopics"
        ],
        "requiresEvidenceLink": true
      },
      {
        "id": "talkDynamics",
        "type": "analyticsCard",
        "metrics": [
          "talkRatioSalesPct",
          "talkRatioClientPct",
          "interruptionsCount",
          "paceWpmSales",
          "paceWpmClient"
        ]
      },
      {
        "id": "topics",
        "type": "checklist",
        "items": [
          "needProblem",
          "budget",
          "timeline",
          "decisionMaker",
          "alternativesCompetitors",
          "technicalFit",
          "securityCompliance",
          "procurement",
          "nextSteps"
        ],
        "autoCheck": true,
        "manualOverride": true
      }
    ],
    "controls": {
      "headerControls": [
        { "id": "toggleLiveAnalysis", "type": "toggle", "default": false },
        { "id": "privacyMode", "type": "toggle", "default": false },
        {
          "id": "sensitivity",
          "type": "slider",
          "range": [0, 100],
          "default": 50
        },
        {
          "id": "coachingAggressiveness",
          "type": "slider",
          "range": [0, 100],
          "default": 40
        }
      ],
      "disclaimer": {
        "required": true,
        "text": "AI guidance may be inaccurate. Use your judgment and ensure participant consent as required by law."
      }
    }
  },

  "privacyCompliance": {
    "consent": {
      "required": true,
      "copy": "Live Analysis uses AI to transcribe and analyze conversation (including tone) to provide coaching. Ensure you have consent from participants where required."
    },
    "redaction": {
      "enabled": true,
      "patterns": ["email", "phone", "creditCard", "bankAccountOptional"],
      "applyTo": ["storedTranscript", "aiRequests", "uiEvidenceSnippets"]
    },
    "retention": {
      "audioDays": 0,
      "transcriptDays": 30,
      "insightsDays": 30,
      "configurable": true
    },
    "security": {
      "inTransit": "TLS",
      "atRest": "AES-256",
      "accessControl": "workspaceRBAC",
      "auditLog": true
    }
  },

  "costControls": {
    "tokenBudget": {
      "maxTokensPerMinute": 2500,
      "strategy": "deltaOnlyPlusCompactMemory",
      "truncateRules": {
        "maxDeltaUtterances": 12,
        "maxEvidenceSnippets": 6,
        "maxMemoryChars": 2500
      }
    },
    "analysisThrottle": {
      "defaultCadenceSec": 15,
      "adaptive": {
        "ifLowSpeech": "increaseTo30s",
        "ifHighSpeech": "keep15sButShortenDelta",
        "ifProviderRateLimit": "degradeToMetricsOnly"
      }
    }
  },

  "observability": {
    "metrics": [
      "endToEndLatencyMs",
      "asrLatencyMs",
      "analysisLatencyMs",
      "wsReconnectCount",
      "audioDropRate",
      "dedupeRate",
      "aiTokenUsage",
      "providerErrors"
    ],
    "logs": {
      "levels": ["info", "warn", "error"],
      "piiSafe": true
    },
    "tracing": {
      "enabled": true,
      "traceIdPropagation": true
    }
  },

  "acceptanceCriteria": [
    "Works on both Web (mic + optional tab audio) and Desktop (mic + system audio).",
    "Committed transcript updates are stable and deduped (no repeating final utterances).",
    "Analysis runs every 15 seconds and updates UI with sentiment/engagement/pain points and coaching suggestions.",
    "Tone scoring (energy/stress/certainty) is shown only when prosody quality gates pass; otherwise confidence drops and weights fall back to text/dynamics.",
    "Client sentiment primarily uses CLIENT role; if role is mixed/unknown, system indicates reduced confidence.",
    "Reconnect resumes streaming without duplicating committed transcript.",
    "User can stop Live Analysis instantly; streaming stops and UI reflects status."
  ],

  "phasedDelivery": [
    {
      "phase": "P0 (Demo/MVP)",
      "scope": [
        "Web mic capture + ElevenLabs realtime transcription via backend proxy",
        "15s analysis loop using transcript only (text-first)",
        "Sentiment + engagement + pain points + 1-2 suggestions",
        "Basic UI (meters + coach panel + timeline)"
      ]
    },
    {
      "phase": "P1 (Desktop-first Reliability)",
      "scope": [
        "Desktop system audio loopback capture for client stream",
        "Role separation by source (mic=sales, system=client)",
        "Prosody tone scoring (energy/stress/certainty) + fusion into sentiment/engagement",
        "Objection taxonomy + topic coverage checklist"
      ]
    },
    {
      "phase": "P2 (Hardening + Intelligence)",
      "scope": [
        "Fallback diarization/clustering for mixed audio scenarios",
        "Adaptive cadence/cost controls",
        "Playbooks per product/company",
        "Team dashboards + call review"
      ]
    }
  ]
}
